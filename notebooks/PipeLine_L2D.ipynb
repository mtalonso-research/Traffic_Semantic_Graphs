{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a46fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from functions.utils_L2D import load_and_restore_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e440404",
   "metadata": {},
   "source": [
    "#### 1. Download Data\n",
    "\n",
    "- To download only one episode, use data_downloader(ep_num,...)\n",
    "\n",
    "- To download a range of episodes, use data_downloader(min_ep,max_ep,...)\n",
    "\n",
    "- Additionally, you can chnge the following directories:\n",
    "\n",
    "    - tabular_data_dir = '../data/raw/L2D/tabular'\n",
    "\n",
    "    - frames_dir = '../data/raw/L2D/frames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cdab3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.load_data_L2D import data_downloader\n",
    "\n",
    "data_downloader(32,n_secs=3,\n",
    "                features={\"tabular\": True,\n",
    "                          \"frames\": {\n",
    "                                'observation.images.front_left': True,\n",
    "                                'observation.images.left_backward': False,\n",
    "                                'observation.images.left_forward': False,\n",
    "                                'observation.images.map': False,\n",
    "                                'observation.images.rear': False,\n",
    "                                'observation.images.right_backward': False,\n",
    "                                'observation.images.right_forward': False,\n",
    "                            }\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44174f1",
   "metadata": {},
   "source": [
    "#### 2. Process Tabular Data & Add Tags\n",
    "\n",
    "- To process only one episode, use process_tabular_data(ep_num,...)\n",
    "\n",
    "- To process a range of episodes, use process_tabular_data(min_ep,max_ep,...)\n",
    "\n",
    "- Additionally, you can change the following directories:\n",
    "\n",
    "    - process_tabular_data:\n",
    "\n",
    "        - source_dir = '../data/raw/L2D/tabular'\n",
    "\n",
    "        - output_dir_processed = '../data/processed_data/L2D'\n",
    "\n",
    "        - output_dir_tags = '../data/semantic_tags/L2D'\n",
    "\n",
    "    - add_data_tags:\n",
    "\n",
    "        - data_dir = '../data/processed/L2D'\n",
    "\n",
    "        - tags_dir='../data/semantic_tags/L2D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7834cf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1019.27it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 44.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from functions.process_tabular_data_L2D import process_tabular_data\n",
    "from functions.process_tags_L2D import add_data_tags\n",
    "\n",
    "process_tabular_data(32,\n",
    "                    overwrite=False, process_columns=True, \n",
    "                    process_osm=True, process_turning=False)\n",
    "add_data_tags(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b47a1",
   "metadata": {},
   "source": [
    "#### 3. Process Frames\n",
    "\n",
    "- Set up with depth model with pip install git+https://github.com/apple/ml-depth-pro.git\n",
    "\n",
    "- To process only one episode, use process_frames(ep_num,...)\n",
    "\n",
    "- To process a range of episodes, use process_tabular_data(min_ep,max_ep,...)\n",
    "\n",
    "- In this case, I have detection and depth set to False to make it run faster. If you have never run this code before, they should be set to true.\n",
    "\n",
    "- Additionally, you can change the following directories:\n",
    "\n",
    "    - input_base_dir = '../data/raw/L2D/frames',\n",
    "    \n",
    "    - output_base_dir = '../data/processed_frames/L2D'\n",
    "\n",
    "- You can also include the following cameras:\n",
    "\n",
    "    - \"observation.images.front_left\",\n",
    "    - \"observation.images.left_forward\", \n",
    "    - \"observation.images.right_forward\",\n",
    "    - \"observation.images.right_backward\",\n",
    "    - \"observation.images.rear\",\n",
    "    - \"observation.images.left_backward\"\n",
    "\n",
    "**Note**: Including additional cameras will help with the depth, speed, etc. but CONSIDERABLY increases running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d70dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Initializing Depth Pro...\n",
      "âœ… Depth Pro model already exists\n",
      "âœ… Depth Pro loaded on cpu\n",
      "ðŸ¤– Initializing RF-DETR model...\n",
      "Loading pretrain weights\n",
      "âœ… RF-DETR model loaded successfully\n",
      "\n",
      "ðŸ”¹ Processing episode 32 with config: {'detection': False, 'depth': False, 'speed': True}\n",
      "  ðŸ“· Camera front_left: 5 frames found\n",
      "  âœ… Processed 5 frames for front_left\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{32: {'front_left': [{'frame': 'frame_00000.jpg',\n",
       "    'detections': 0,\n",
       "    'path': '../data/processed_frames/L2D/Episode000032/front_left_Segmented/frame_00000.jpg',\n",
       "    'json': '../data/processed_frames/L2D/Episode000032/front_left_Annotations/frame_00000.json',\n",
       "    'has_depth': False},\n",
       "   {'frame': 'frame_00001.jpg',\n",
       "    'detections': 0,\n",
       "    'path': '../data/processed_frames/L2D/Episode000032/front_left_Segmented/frame_00001.jpg',\n",
       "    'json': '../data/processed_frames/L2D/Episode000032/front_left_Annotations/frame_00001.json',\n",
       "    'has_depth': False},\n",
       "   {'frame': 'frame_00002.jpg',\n",
       "    'detections': 0,\n",
       "    'path': '../data/processed_frames/L2D/Episode000032/front_left_Segmented/frame_00002.jpg',\n",
       "    'json': '../data/processed_frames/L2D/Episode000032/front_left_Annotations/frame_00002.json',\n",
       "    'has_depth': False},\n",
       "   {'frame': 'frame_00003.jpg',\n",
       "    'detections': 0,\n",
       "    'path': '../data/processed_frames/L2D/Episode000032/front_left_Segmented/frame_00003.jpg',\n",
       "    'json': '../data/processed_frames/L2D/Episode000032/front_left_Annotations/frame_00003.json',\n",
       "    'has_depth': False},\n",
       "   {'frame': 'frame_00004.jpg',\n",
       "    'detections': 0,\n",
       "    'path': '../data/processed_frames/L2D/Episode000032/front_left_Segmented/frame_00004.jpg',\n",
       "    'json': '../data/processed_frames/L2D/Episode000032/front_left_Annotations/frame_00004.json',\n",
       "    'has_depth': False}]}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions.process_frames_L2D import process_frames\n",
    "\n",
    "process_frames(32,\n",
    "               cameras_on=[\"observation.images.front_left\"],\n",
    "               run_dict={\"detection\": False,\n",
    "                         \"depth\": False,\n",
    "                         \"speed\": True},\n",
    "                verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f35ae0",
   "metadata": {},
   "source": [
    "#### 4. Generate Graphs\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55de35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d524dec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6701240b79b04d9b9a63fc02b6b4de3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'selector': 'node', 'style': {'label': 'dâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functions.graphs_L2D import combined_graph_viewer\n",
    "\n",
    "ep_num = 32\n",
    "with open(f\"../data/graphical/L2D/{ep_num}_graph.json\", \"r\") as f:\n",
    "    graph_data = json.load(f)\n",
    "\n",
    "cyto = combined_graph_viewer({'graph':graph_data})\n",
    "display(cyto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b796283d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f91785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8df1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
