{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a46fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "import torch.optim as optim\n",
    "import json\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5259c",
   "metadata": {},
   "source": [
    "## Phase 1: Generating the Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e440404",
   "metadata": {},
   "source": [
    "#### 1. Download Data\n",
    "\n",
    "- To download only one episode, use data_downloader(ep_num,...)\n",
    "\n",
    "- To download a range of episodes, use data_downloader(min_ep,max_ep,...)\n",
    "\n",
    "- To download a list of episodes, use data_downloader(list,...)\n",
    "\n",
    "- n_secs defines the interval of times between frames (default is set to 3 seconds)\n",
    "\n",
    "- Additionally, you can chnge the following directories:\n",
    "\n",
    "    - tabular_data_dir = '../data/raw/L2D/tabular'\n",
    "\n",
    "    - frames_dir = '../data/raw/L2D/frames'\n",
    "\n",
    "    - metadata_dir = '../data/raw/L2D/metadata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cdab3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached metadata at ../data/raw/L2D/metadata/metadata.parquet\n",
      "Downloading tabular chunk 0, file 0...\n",
      "Downloading video chunk 0, file 6 for observation.images.front_left...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa16745bfe9f4023b1a8a81d065f93ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "videos/observation.images.front_left/chu(…):   0%|          | 0.00/482M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All done. Temporary files cleaned up.\n"
     ]
    }
   ],
   "source": [
    "from functions.load_data_L2D import data_downloader\n",
    "\n",
    "data_downloader(0,n_secs=3,\n",
    "                features={\"tabular\": True,\n",
    "                          \"frames\": {\n",
    "                                'observation.images.front_left': True,\n",
    "                                'observation.images.left_backward': False,\n",
    "                                'observation.images.left_forward': False,\n",
    "                                'observation.images.map': False,\n",
    "                                'observation.images.rear': False,\n",
    "                                'observation.images.right_backward': False,\n",
    "                                'observation.images.right_forward': False,\n",
    "                            }\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44174f1",
   "metadata": {},
   "source": [
    "#### 2. Process Tabular Data & Add Tags\n",
    "\n",
    "- To process only one episode, use process_tabular_data(ep_num,...)\n",
    "\n",
    "- To process a range of episodes, use process_tabular_data(min_ep,max_ep,...)\n",
    "\n",
    "- To process a list of episodes, use process_tabular_data(list,...)\n",
    "\n",
    "- Additionally, you can change the following directories:\n",
    "\n",
    "    - process_tabular_data:\n",
    "\n",
    "        - source_dir = '../data/raw/L2D/tabular'\n",
    "\n",
    "        - output_dir_processed = '../data/processed_data/L2D'\n",
    "\n",
    "        - output_dir_tags = '../data/semantic_tags/L2D'\n",
    "\n",
    "    - add_data_tags:\n",
    "\n",
    "        - data_dir = '../data/processed/L2D'\n",
    "\n",
    "        - tags_dir='../data/semantic_tags/L2D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7834cf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:34<00:00, 34.01s/it, errors=3 / 7]\n"
     ]
    }
   ],
   "source": [
    "from functions.process_tabular_data_L2D import process_tabular_data\n",
    "\n",
    "process_tabular_data(0,\n",
    "                    overwrite=True, process_columns=True, \n",
    "                    process_osm=True, process_turning=True,\n",
    "                    time_sleep=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7159d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating semantic tags: 100%|██████████| 1/1 [00:00<00:00, 59.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from functions.process_tags_L2D import add_data_tags\n",
    "\n",
    "add_data_tags(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b47a1",
   "metadata": {},
   "source": [
    "#### 3. Process Frames\n",
    "\n",
    "- Set up with depth model with pip install git+https://github.com/apple/ml-depth-pro.git\n",
    "\n",
    "- Set up rfdetr with pip install --ignore-installed rfdetr\n",
    "\n",
    "- To process only one episode, use process_frames(ep_num,...)\n",
    "\n",
    "- To process a range of episodes, use process_frames(min_ep,max_ep,...)\n",
    "\n",
    "- To process a list of episodes, use process_frames(list,...)\n",
    "\n",
    "- Additionally, you can change the following directories:\n",
    "\n",
    "    - input_base_dir = '../data/raw/L2D/frames',\n",
    "    \n",
    "    - output_base_dir = '../data/processed_frames/L2D'\n",
    "\n",
    "- You can also include the following cameras:\n",
    "\n",
    "    - \"observation.images.front_left\",\n",
    "    - \"observation.images.left_forward\", \n",
    "    - \"observation.images.right_forward\",\n",
    "    - \"observation.images.right_backward\",\n",
    "    - \"observation.images.rear\",\n",
    "    - \"observation.images.left_backward\"\n",
    "\n",
    "**Note**: Including additional cameras will help with the depth, speed, etc. but CONSIDERABLY increases running time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22d70dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]Model is not optimized for inference. Latency may be higher than expected. You can optimize the model for inference by calling model.optimize_for_inference().\n",
      "100%|██████████| 1/1 [07:54<00:00, 474.58s/it]\n"
     ]
    }
   ],
   "source": [
    "from functions.process_frames_L2D import process_frames\n",
    "\n",
    "process_frames(0,\n",
    "               cameras_on=[\"observation.images.front_left\"],\n",
    "               run_dict={\"detection\": True,\n",
    "                         \"depth\": True,\n",
    "                         \"speed\": True,\n",
    "                         'overwrite': True},\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50d8e600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.89it/s]\n"
     ]
    }
   ],
   "source": [
    "from functions.process_lanes_L2D import lane_processing\n",
    "summary = lane_processing(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f35ae0",
   "metadata": {},
   "source": [
    "#### 4. Generate Graphs (Need to Update for the Addition of Speed)\n",
    "\n",
    "- To process only one episode, use generate_graphs(ep_num,...)\n",
    "\n",
    "- To process a range of episodes, use generate_graphs(min_ep,max_ep,...)\n",
    "\n",
    "- To process a list of episodes, use generate_graphs(list,...)\n",
    "\n",
    "- Additionally, you can change the following directories:\n",
    "\n",
    "    - source_data_dir = '../data/processed/L2D',\n",
    "    \n",
    "    - processed_frame_dir = '../data/processed_frames/L2D',\n",
    "                    \n",
    "    - output_dir = '../data/graphical/L2D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f55de35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from functions.graphs import generate_graphs\n",
    "generate_graphs(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f9d08",
   "metadata": {},
   "source": [
    "#### Quick Visualization of Graph & Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9cacd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962c3b58687f4ba2b08481ea4d8d3b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'cola'}, cytoscape_style=[{'selector': 'node', 'style': {'label': 'd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from functions.graphs import combined_graph_viewer\n",
    "\n",
    "ep_num = 0\n",
    "with open(f\"../data/graphical/l2d/{ep_num}_graph.json\", \"r\") as f:\n",
    "    graph_data = json.load(f)\n",
    "\n",
    "cyto = combined_graph_viewer({'graph':graph_data})\n",
    "display(cyto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e21adf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'episode_index': 0,\n",
       " 'action_tag': 'straight',\n",
       " 'traffic_control_tag': 'unmarked',\n",
       " 'road_feature_tags': [],\n",
       " 'environment_tags': ['clouds',\n",
       "  'day',\n",
       "  'low_visibility_possible',\n",
       "  'off_peak_hours',\n",
       "  'weekend',\n",
       "  'winter_conditions_possible']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep_num = 0\n",
    "with open(f\"../data/semantic_tags/l2d/episode_{ep_num:06}.json\", \"r\") as f:\n",
    "    graph_tags = json.load(f)\n",
    "graph_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eb2db78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                            Veh_FL_A_1\n",
       "type                                                             vehicle\n",
       "lane_classification                                              in_lane\n",
       "lane_overlap_ratio                                              0.408845\n",
       "distance_m                                                      2.072108\n",
       "dist_to_ego                                                      2.39308\n",
       "speed_ms                                                        2.736617\n",
       "speed_kmh                                                        9.85182\n",
       "velocity_ms            [-0.3257415254237288, 2.7171610169491527, 8.03...\n",
       "velocity_kmh           [-1.1726694915254237, 9.78177966101695, 28.914...\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functions.graphs import graph_to_dfs\n",
    "\n",
    "nodes_df, edges_df = graph_to_dfs(graph_data)\n",
    "nodes_df.iloc[8].dropna()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sem_graphs (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
