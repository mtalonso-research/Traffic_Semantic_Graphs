# Traffic Semantic Graphs

<img src="figures/project_overview.png" alt="project overview">

## ğŸ“ Directory Overview

```plaintext
TRAFFIC_SEMANTIC_GRAPHS/
â”œâ”€â”€ data/                            # Local-only: raw and processed data (not included in repo)
â”‚   â”œâ”€â”€ distributions/               # Data distributions
â”‚   â”œâ”€â”€ graphical/                   # Graph files for L2D and NuPlan datasets
â”‚   â”œâ”€â”€ graphical_final/             # Final graphical data after processing and filtering
â”‚   â”œâ”€â”€ processed/                   # Processed tabular data
â”‚   â”œâ”€â”€ processed_frames/            # Processed image frames (e.g., YOLO, depth outputs)
â”‚   â”œâ”€â”€ raw/                         # Raw inputs (images, tabular)
â”‚   â”œâ”€â”€ semantic_tags/               # Semi-manually-generated semantic tags
â”‚   â””â”€â”€ temporary_data/              # Temporary data storage
â”œâ”€â”€ figures/                         # Project figures and visualizations
â”‚   â”œâ”€â”€ project_overview.pdf
â”‚   â””â”€â”€ project_overview.png
â”œâ”€â”€ ml-depth-pro/                    # Machine learning depth prediction project
â”‚   â””â”€â”€ checkpoints/                 # Checkpoints for ML models
â”œâ”€â”€ nuplan-devkit/                   # NuPlan development kit
â”œâ”€â”€ scripts/                         # Scripts for data processing and visualization
â”‚   â”œâ”€â”€ 1A_l2d_processing.py         # L2D data processing script
â”‚   â”œâ”€â”€ 1B_nup_processing.py         # NuPlan data processing script
â”‚   â”œâ”€â”€ 1C_final_processing.py       # Final processing script
â”‚   â””â”€â”€ scene_visualizer.py          # Scene visualization script
â”œâ”€â”€ src/                             # Main source code
â”‚   â”œâ”€â”€ data_processing/             # Modules for data loading and processing
â”‚   â”‚   â”œâ”€â”€ filtering.py
â”‚   â”‚   â”œâ”€â”€ final_post_processing.py
â”‚   â”‚   â”œâ”€â”€ l2d_generate_graphs.py
â”‚   â”‚   â”œâ”€â”€ l2d_lane_processing.py
â”‚   â”‚   â”œâ”€â”€ l2d_load_data.py
â”‚   â”‚   â”œâ”€â”€ l2d_process_frames.py
â”‚   â”‚   â”œâ”€â”€ l2d_process_pqts.py
â”‚   â”‚   â”œâ”€â”€ l2d_process_tags.py
â”‚   â”‚   â”œâ”€â”€ nup_load_data.py
â”‚   â”‚   â””â”€â”€ nup_process_jsons.py
â”‚   â”œâ”€â”€ risk_analysis.py             # Risk analysis module
â”‚   â”œâ”€â”€ utils.py                     # Utility functions
â”‚   â””â”€â”€ visualizations.py            # Visualization functions
â””â”€â”€ README.md                        # This file

```
**Note:** The actual data files are not included in the repository due to storage limitations.

## Phase 1: Data Processing

This phase involves processing the raw data from the L2D and NuPlan datasets into a format suitable for risk analysis.

### 1A: L2D Data Processing

The `1A_l2d_processing.py` script processes the L2D dataset.

**Usage:**
```bash
python -m scripts.1A_l2d_processing [-h] [--min_ep MIN_EP] [--max_ep MAX_EP] [--download] [--process_tabular] [--add_tags] [--process_frames] [--process_lanes] [--generate_graphs] [--all]
```

**Arguments:**
- `-h, --help`: show this help message and exit
- `--min_ep MIN_EP`: Minimum episode number to process.
- `--max_ep MAX_EP`: Maximum episode number to process.
- `--download`: Run data download step.
- `--process_tabular`: Run tabular data processing step.
- `--add_tags`: Run tag processing step.
- `--process_frames`: Run frame processing step.
- `--process_lanes`: Run lane processing step.
- `--generate_graphs`: Run graph generation step.
- `--all`: Run all steps (default if no flags are set).

To run the entire L2D processing pipeline, use the following command:
```bash
python -m scripts.1A_l2d_processing --all
```

### 1B: NuPlan Data Processing

The `1B_nup_processing.py` script processes the NuPlan dataset.

**Usage:**
```bash
python -m scripts.1B_nup_processing [-h] [--city CITY] [--file_min FILE_MIN] [--file_max FILE_MAX] [--episodes EPISODES [EPISODES ...]] [--load] [--latlon] [--weather] [--weather_codes] [--temporal] [--tags]
```

**Arguments:**
- `-h, --help`: show this help message and exit
- `--city CITY`: City to process (boston or pittsburgh).
- `--file_min FILE_MIN`: Minimum DB file index to process (inclusive).
- `--file_max FILE_MAX`: Maximum DB file index to process (exclusive). Use 'none' for all after file_min.
- `--episodes EPISODES [EPISODES ...]`: Episodes to Process.
- `--load`: Run only the data loading step.
- `--latlon`: Run only the lat/lon addition step.
- `--weather`: Run only the weather enrichment step.
- `--weather_codes`: Run only the weather code replacement step.
- `--temporal`: Run only the temporal feature addition step.
- `--tags`: Run only the tag extraction step.

To run the NuPlan processing for a specific city (e.g., Boston) and a specific step (e.g., tags), use the following command:
```bash
python -m scripts.1B_nup_processing --city boston --tags
```

To run all steps, you can omit the step-specific flags:
```bash
python -m scripts.1B_nup_processing --city boston
```

### 1C: Final Post-Processing

The `1C_final_processing.py` script performs final post-processing on the generated graph data.

**Usage:**
```bash
python -m scripts.1C_final_processing [-h] [--process_l2d] [--process_nuplan_boston] [--process_nuplan_pittsburgh]
```

**Arguments:**
- `-h, --help`: show this help message and exit
- `--process_l2d`: Run L2D final processing
- `--process_nuplan_boston`: Run nuPlan Boston final processing
- `--process_nuplan_pittsburgh`: Run nuPlan Pittsburgh final processing

To run the final processing for a specific dataset, use the corresponding flag. For example, to process the L2D dataset:
```bash
python -m scripts.1C_final_processing --process_l2d
```
